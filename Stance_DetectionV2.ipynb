{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternus - Vera : Stance Detection\n",
    "\n",
    "Author: Vidhi Shah\n",
    "***\n",
    "The idea of fake news is often referred to as click-bait in social trends and is defined as a “made up story with an intention to deceive, geared towards getting clicks”. Some news articles have titles which grab a reader’s interest. Yet, the author only emphasizes a specific part of the article in the title. If the article itself does not focus on or give much truth to what the title had written, the news may be misleading.\n",
    "\n",
    "The goal of this project is to use natural language processing techniques to automate stance detection, since it is not practical for humans to fact check every piece of information produced by the media.\n",
    "\n",
    "Stance detection is a method used to determine the quality of a news article by taking into consideration what other organisations write about the same headline. A body of text is claimed to agree, disagree, discuss, or be unrelated to a headline, Fake News Challenge (2016) Stance detection is the method that will be used to determine the quality of a news source. \n",
    "\n",
    "From the [FakeChallenge.org](http://fakenewschallenge.org) a dataset hase been provided which consists of a headline and a body of text. This body of text may be from a different article. Allowing bodies of text from different articles allows this system to take into account what the other organisations are saying about he same headline. The output of the system will be the stance of the body of text related to the title. The system will support will support the following stance types:\n",
    "- Agrees\n",
    "- Disagrees\n",
    "- Discusses\n",
    "- Unrelated\n",
    "\n",
    "With this system, for a set of news headlines, statistics can be gathered with respect to the stances. With these statistics, a user can come to their own conclusion of whether a new organisation has reputable news sources. To achieve these stances, this system will train on the data supplied by the fake news challenge. This data will provide the stance along with the headline and body to allow the system to learn which word combinations lead to which stance. For testing, data will be provided without the stances.\n",
    "\n",
    "This project was inspired by the Fake News Challenge (FNC)\n",
    "[FakeChallenge.org](http://fakenewschallenge.org) <br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import pylab as py\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import coo_matrix\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "import csv, random, numpy, os, re, scipy, gensim\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from langdetect import detect\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from csv import DictReader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "# import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet():\n",
    "    def __init__(self, path=\"data\"):\n",
    "        self.path = path\n",
    "\n",
    "        print(\"Reading dataset\")\n",
    "        bodies = \"train_bodies.csv\"\n",
    "        stances = \"train_stances.csv\"\n",
    "\n",
    "        self.stances = self.read(stances)\n",
    "        articles = self.read(bodies)\n",
    "        self.articles = dict()\n",
    "\n",
    "        #make the body ID an integer value\n",
    "        for s in self.stances:\n",
    "            s['Body ID'] = int(s['Body ID'])\n",
    "\n",
    "        #copy all bodies into a dictionary\n",
    "        for article in articles:\n",
    "            self.articles[int(article['Body ID'])] = article['articleBody']\n",
    "\n",
    "        print(\"Total stances: \" + str(len(self.stances)))\n",
    "        print(\"Total bodies: \" + str(len(self.articles)))\n",
    "\n",
    "\n",
    "\n",
    "    def read(self,filename):\n",
    "        rows = []\n",
    "        with open(self.path + \"/\" + filename, \"r\", encoding='utf-8') as table:\n",
    "            r = DictReader(table)\n",
    "\n",
    "            for line in r:\n",
    "                rows.append(line)\n",
    "        return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.stances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ids(file,base):\n",
    "    ids = []\n",
    "    with open(base+\"/\"+file,\"r\") as f:\n",
    "        for line in f:\n",
    "            ids.append(int(line))\n",
    "        return ids\n",
    "    \n",
    "def split(dataset, base=\"splits\"):\n",
    "    if not (os.path.exists(base+\"/\"+\"training_ids.txt\")\n",
    "            and os.path.exists(base+\"/\"+\"dev_ids.txt\") and os.path.exists(base+\"/\"+\"test_ids.txt\")):\n",
    "        raise Exception(\"There is an error and the dataset reader cannot find the \"\n",
    "                        \"{training_ids|test_ids|dev_ids}.txt file. Please make sure your python paths \"\n",
    "                        \"are configured correctly\")\n",
    "\n",
    "    training_ids = read_ids(\"training_ids.txt\",base)\n",
    "    dev_ids = read_ids(\"dev_ids.txt\",base)\n",
    "    test_ids = read_ids(\"test_ids.txt\",base)\n",
    "\n",
    "    #return the stances that meet these criteria\n",
    "    training_stances = []\n",
    "    dev_stances = []\n",
    "    test_stances = []\n",
    "\n",
    "    for stance in dataset.stances:\n",
    "        if stance['Body ID'] in training_ids:\n",
    "            training_stances.append(stance)\n",
    "        elif stance['Body ID'] in dev_ids:\n",
    "            dev_stances.append(stance)\n",
    "        elif stance['Body ID'] in test_ids:\n",
    "            test_stances.append(stance)\n",
    "\n",
    "\n",
    "    return {\"training\":training_stances, \"dev\":dev_stances, \"test\": test_stances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = split(dataset)\n",
    "\n",
    "# in the format: Stance, Headline, BodyID\n",
    "training_data = data_splits['training']\n",
    "dev_data = data_splits['dev']\n",
    "test_data = data_splits['test'] # currently 0 test points\n",
    "\n",
    "# Change the number of training examples used.\n",
    "N = int(len(training_data) * 1.0)\n",
    "training_data = training_data[:N]\n",
    "\n",
    "print(\"Training size:\", len(training_data))\n",
    "print(\"Dev size:\", len(dev_data))\n",
    "print(\"Test data:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bodies of training data points\n",
    "def get_bodies(data):\n",
    "    bodies = []\n",
    "    for i in range(len(data)):\n",
    "        bodies.append(dataset.articles[data[i]['Body ID']])\n",
    "    return bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the headlines of training data points\n",
    "def get_headlines(data):\n",
    "    headlines = []\n",
    "    for i in range(len(data)):\n",
    "        headlines.append(data[i]['Headline'])\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bodies and headlines for dev and training data\n",
    "training_bodies = get_bodies(training_data)\n",
    "training_headlines = get_headlines(training_data)\n",
    "dev_bodies = get_bodies(dev_data)\n",
    "dev_headlines = get_headlines(dev_data)\n",
    "test_bodies = get_bodies(test_data)\n",
    "test_headlines = get_headlines(test_data)\n",
    "\n",
    "print(len(training_bodies))\n",
    "print(len(training_headlines))\n",
    "print(len(dev_bodies))\n",
    "print(len(dev_headlines))\n",
    "print(len(test_bodies))\n",
    "print(len(test_headlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_tfidf(training_headlines, training_bodies, dev_headlines=\"\", dev_bodies=\"\", test_headlines=\"\", test_bodies=\"\"):\n",
    "    # Body vectorisation\n",
    "    body_vectorizer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, stop_words='english')#, max_features=1024)\n",
    "    bodies_tfidf = body_vectorizer.fit_transform(training_bodies)\n",
    "\n",
    "    # Headline vectorisation\n",
    "    headline_vectorizer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, stop_words='english')#, max_features=1024)\n",
    "    headlines_tfidf = headline_vectorizer.fit_transform(training_headlines)\n",
    "\n",
    "    # Tranform dev/test bodies and headlines using the trained vectorizer (trained on training data)\n",
    "    bodies_tfidf_dev = body_vectorizer.transform(dev_bodies)\n",
    "    headlines_tfidf_dev = headline_vectorizer.transform(dev_headlines)\n",
    "\n",
    "    bodies_tfidf_test = body_vectorizer.transform(test_bodies)\n",
    "    headlines_tfidf_test = headline_vectorizer.transform(test_headlines)\n",
    "    \n",
    "    feature_names = np.array(body_vectorizer.get_feature_names())\n",
    "    sorted_by_idf = np.argsort(body_vectorizer.idf_) \n",
    "    print('Features with lowest and highest idf in the body vector:\\n')\n",
    "    # The token which appears maximum times but it is also in all documents, has its idf the lowest\n",
    "    print(\"Features with lowest idf:\\n{}\".format(\n",
    "    feature_names[sorted_by_idf[:10]]))\n",
    "    # The tokens can have the most idf weight because they are the only tokens that appear in one document only\n",
    "    print(\"\\nFeatures with highest idf:\\n{}\".format(\n",
    "    feature_names[sorted_by_idf[-10:]]))\n",
    "\n",
    "    # Combine body_tfdif with headline_tfidf for every data point. \n",
    "    training_tfidf = scipy.sparse.hstack([bodies_tfidf, headlines_tfidf])\n",
    "    dev_tfidf = scipy.sparse.hstack([bodies_tfidf_dev, headlines_tfidf_dev])\n",
    "    test_tfidf = scipy.sparse.hstack([bodies_tfidf_test, headlines_tfidf_test])\n",
    "\n",
    "    return training_tfidf, dev_tfidf, test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "# Tokenisation, Normalisation, Capitalisation, Non-alphanumeric removal, Stemming-Lemmatization\n",
    "def preprocess(string):\n",
    "    # to lowercase, non-alphanumeric removal\n",
    "    step1 = \" \".join(re.findall(r'\\w+', string, flags=re.UNICODE)).lower()\n",
    "    step2 = [lemmatizer.lemmatize(t).lower() for t in nltk.word_tokenize(step1)]\n",
    "\n",
    "    return step2\n",
    "\n",
    "# Function for extracting word overlap\n",
    "def extract_word_overlap(headlines, bodies):\n",
    "    word_overlap = []\n",
    "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
    "        preprocess_headline = preprocess(headline)\n",
    "        preprocess_body = preprocess(body)\n",
    "        \n",
    "        # Lenght of common words b/w body and headline / Length of all the words of body & headline\n",
    "        features = len(set(preprocess_headline).intersection(preprocess_body)) / float(len(set(preprocess_headline).union(preprocess_body)))\n",
    "        word_overlap.append(features)\n",
    "        \n",
    "        # Convert the list to a sparse matrix (in order to concatenate the cos sim with other features)\n",
    "        word_overlap_sparse = scipy.sparse.coo_matrix(numpy.array(word_overlap)) \n",
    "    return word_overlap_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting the cosine similarity between bodies and headlines. \n",
    "def extract_cosine_similarity(headlines, bodies):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2), lowercase=True, stop_words='english')#, max_features=1024)\n",
    "    \n",
    "    cos_sim_features = []\n",
    "    for i in range(0, len(bodies)):\n",
    "        body_vs_headline = []\n",
    "        body_vs_headline.append(bodies[i])\n",
    "        body_vs_headline.append(headlines[i])\n",
    "        tfidf = vectorizer.fit_transform(body_vs_headline)\n",
    "        \n",
    "        cosine_similarity = (tfidf * tfidf.T).A\n",
    "        cos_sim_features.append(cosine_similarity[0][1])\n",
    "\n",
    "    # Convert the list to a sparse matrix (in order to concatenate the cos sim with other features)\n",
    "    cos_sim_array = scipy.sparse.coo_matrix(numpy.array(cos_sim_features)) \n",
    "\n",
    "    return cos_sim_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for combining features of various types (lists, coo_matrix, np.array etc.)\n",
    "def combine_features(tfidf_vectors, cosine_similarity, word_overlap):\n",
    "    combined_features =  sparse.bmat([[tfidf_vectors, word_overlap.T, cosine_similarity.T]])\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting features\n",
    "# Feautres: 1) Word Overlap, 2) TF-IDF vectors, 3) Cosine similarity, 4) Word embeddings\n",
    "def extract_features(train, dev, test):\n",
    "# Get bodies and headlines for dev and training data\n",
    "    training_bodies = get_bodies(training_data)\n",
    "    training_headlines = get_headlines(training_data)\n",
    "    dev_bodies = get_bodies(dev_data)\n",
    "    dev_headlines = get_headlines(dev_data)\n",
    "    test_bodies = get_bodies(test_data)\n",
    "    test_headlines = get_headlines(test_data)\n",
    "\n",
    "    # Extract tfidf vectors\n",
    "    print(\"\\t-Extracting tfidf vectors..\")\n",
    "    training_tfidf, dev_tfidf, test_tfidf = extract_tfidf(training_headlines, training_bodies, dev_headlines, dev_bodies, test_headlines, test_bodies)\n",
    "    print(\"\\t-Tfidf vectors extracted..\")\n",
    "\n",
    "    # Extract word overlap \n",
    "    print(\"\\t-Extracting word overlap..\")\n",
    "    training_overlap = extract_word_overlap(training_headlines, training_bodies)\n",
    "    dev_overlap = extract_word_overlap(dev_headlines, dev_bodies)\n",
    "    test_overlap = extract_word_overlap(test_headlines, test_bodies)\n",
    "    print(\"\\t-Word overlap extracted..\")\n",
    "\n",
    "#     # Extract cosine similarity between bodies and headlines. \n",
    "    print(\"\\t-Extracting cosine similarity..\")\n",
    "    training_cos = extract_cosine_similarity(training_headlines, training_bodies)\n",
    "    dev_cos = extract_cosine_similarity(dev_headlines, dev_bodies)\n",
    "    test_cos = extract_cosine_similarity(test_headlines, test_bodies)\n",
    "    print(\"\\t-Cosine similarity extracted..\")\n",
    "\n",
    "    # Combine the features\n",
    "    training_features = combine_features(training_tfidf, training_cos, training_overlap)\n",
    "    dev_features = combine_features(dev_tfidf, dev_cos, dev_overlap)\n",
    "    test_features = combine_features(test_tfidf, test_cos, test_overlap)\n",
    "    print(\"\\t-Combined features returned..\")\n",
    "\n",
    "    return training_features, dev_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "\n",
    "print(\"[2] Extracting features.. \")\n",
    "extract_features(training_data, dev_data, test_data)\n",
    "training_features, dev_features, test_features = extract_features(training_data, dev_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['agree', 'disagree', 'discuss', 'unrelated']\n",
    "\n",
    "def report_score(test,pred,algo):\n",
    "    #accuracy calculation\n",
    "    accuracy = accuracy_score(test,pred)\n",
    "    print('\\n Accuracy_score for %s = %s \\n'%(algo,accuracy))\n",
    "    \n",
    "    #confusion_matrix\n",
    "    mat = confusion_matrix(test,pred)\n",
    "    fig, ax = plt.subplots(figsize=(11,11))  \n",
    "    ax.set_title(\"Confusion Matrix for %s\" %algo)\n",
    "    sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,cmap=\"icefire\",\n",
    "                xticklabels=classes,yticklabels=classes,linewidths=.3, ax=ax)\n",
    "    plt.xlabel('True label')\n",
    "    plt.ylabel('Predicted label');\n",
    "\n",
    "    #classification report\n",
    "    cls = classification_report(test,pred, target_names=classes)\n",
    "    print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating targets\n",
    "targets_tr = [a['Stance'] for a in training_data]\n",
    "targets_dev = [a['Stance'] for a in dev_data]\n",
    "targets_test = [a['Stance'] for a in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(f):\n",
    "    if f == 'unrelated':\n",
    "        return 0\n",
    "    elif f == 'disagree':\n",
    "        return 1\n",
    "    elif f == 'discuss':\n",
    "        return 2\n",
    "    elif f == 'agree':\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "y = [change(x) for x in targets_tr]\n",
    "y_test = [change(x) for x in targets_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, text):\n",
    "        predicted = self.logR_pipeline.predict([text])\n",
    "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
    "        return bool(predicted), float(predicedProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model\n",
    "print(\"[3] Fitting model..\")\n",
    "print(\"\\t-Logistic Regression\")\n",
    "lr = LogisticRegression(C = 1.0, class_weight='balanced', solver=\"lbfgs\", max_iter=150) \n",
    "y_pred_lr = lr.fit(training_features, targets_tr).predict(test_features)\n",
    "# Evaluation\n",
    "print(\"[4] Evaluating model..\")\n",
    "report_score(targets_test, y_pred_lr,'Logistic Regression')\n",
    "print(\"\\t-Done with Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[3] Fitting model..\")\n",
    "print(\"\\t-Random Forest Classifier\")\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=12345)\n",
    "y_pred_rf = rf.fit(training_features, targets_tr).predict(test_features)\n",
    "# Evaluation\n",
    "print(\"[4] Evaluating model..\")\n",
    "report_score(targets_test, y_pred_rf,'Random Forest Classifier')\n",
    "print(\"\\t-Done with Random Forest Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[3] Fitting model..\")\n",
    "print(\"\\t-Multinomial Naive Bayes\")\n",
    "nb = MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
    "y_pred_nb = nb.fit(training_features, targets_tr).predict(test_features)\n",
    "# Evaluation\n",
    "print(\"[4] Evaluating model..\")\n",
    "report_score(targets_test, y_pred_nb,'Multinomial Naive Bayes')\n",
    "print(\"\\t-Done with Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[3] Fitting model..\")\n",
    "print(\"\\t-XGBoost Classifier\")\n",
    "xgb = XGBClassifier()\n",
    "y_pred_xgb = xgb.fit(training_features, targets_tr).predict(test_features)\n",
    "# Evaluation\n",
    "print(\"[4] Evaluating model..\")\n",
    "report_score(targets_test, y_pred_nb,'XGBoost')\n",
    "print(\"\\t-Done with XGBoost Classifier\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6b989f8aea76d281d40c171688fb68eaa44ba401600b93bc7d7cc3f2b5fca20"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
